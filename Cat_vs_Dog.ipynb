{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cat vs Dog.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkalim/Deep-Learning/blob/master/Cat_vs_Dog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "aGTn6BcGM3VY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###### Mount Google Drive #######\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IOT7n49SND_D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Import Libraries\n",
        "\n",
        "from keras.applications.xception import Xception\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense , Flatten , Dropout\n",
        "from keras.optimizers import Adam ,RMSprop\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers.convolutional import *\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "import cv2\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import matplotlib.image as img\n",
        "from keras.callbacks import EarlyStopping , ModelCheckpoint , ReduceLROnPlateau\n",
        "from keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bm_LsMiSBpMf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Load and Preprocess Data\n",
        "\n",
        "image_dim = 256\n",
        "set_trainable = False\n",
        "\n",
        "train_path = r\"/content/drive/My Drive/AI/DL/Cats vs Dogs/Train\"\n",
        "valid_path = r\"/content/drive/My Drive/AI/DL/Cats vs Dogs/Valid\"\n",
        "test_path =  r\"/content/drive/My Drive/AI/DL/Cats vs Dogs/Test\"\n",
        "\n",
        "train_datagen = ImageDataGenerator( rescale=1./255,\n",
        "                                    rotation_range=40,\n",
        "                                    shear_range=0.3,\n",
        "                                    zoom_range=0.2,\n",
        "                                    horizontal_flip=True,\n",
        "                                    fill_mode='nearest')\n",
        "\n",
        "valid_datagen = ImageDataGenerator( rescale=1./255,\n",
        "                                    rotation_range=40,\n",
        "                                    shear_range=0.3,\n",
        "                                    zoom_range=0.2,\n",
        "                                    horizontal_flip=True,\n",
        "                                    fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator( rescale=1./255)\n",
        "\n",
        "train_batches = train_datagen.flow_from_directory(train_path, target_size=(image_dim,image_dim), classes=['Cat', 'Dog'], batch_size = 10)\n",
        "valid_batches = valid_datagen.flow_from_directory(valid_path, target_size=(image_dim,image_dim), classes=['Cat', 'Dog'], batch_size = 10)\n",
        "test_batches = test_datagen.flow_from_directory(test_path, target_size=(image_dim,image_dim), classes=['Cat', 'Dog'], batch_size = 1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tcbXvHIxBpOw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Load the Model\n",
        "\n",
        "conv_base = Xception(weights='imagenet', include_top=False, input_shape=(image_dim,image_dim,3))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(layers.Dense(2, activation='softmax'))\n",
        "\n",
        "conv_base.trainable = True\n",
        "\n",
        "'''\n",
        "for layer in conv_base.layers:\n",
        "  if layer.name == 'block5_conv1':\n",
        "    set_trainable = True\n",
        "  if set_trainable:\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False\n",
        "'''\n",
        "model.summary() \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3ViXozdaBpR6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Compile and Train the Model\n",
        "\n",
        "callbacks_list = [ ModelCheckpoint(filepath=\"/content/drive/My Drive/AI/DL/Cats vs Dogs/Trained_Model_256.h5\", monitor='val_loss', save_best_only=True), ReduceLROnPlateau(monitor='val_loss',factor=0.1, patience=3) ]\n",
        "\n",
        "model.compile(Adam(lr = 0.0001), loss = 'categorical_crossentropy',metrics = ['accuracy'])  \n",
        "\n",
        "history = model.fit_generator(train_batches, steps_per_epoch=300, validation_data = valid_batches, callbacks=callbacks_list, validation_steps=100, epochs =40)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cpz0c_O4B4HY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Predict using the trained model\n",
        "\n",
        "image = img.imread(r\"/content/drive/My Drive/AI/DL/test1/6.jpg\")\n",
        "\n",
        "print('saving the model')\n",
        "model.save(r\"/content/drive/My Drive/AI/DL/Cats vs Dogs/Trained_Model.h5\")\n",
        "print('model saved')\n",
        "\n",
        "image = cv2.resize(image , (image_dim,image_dim))\n",
        "image = image.astype('float32')\n",
        "image = image/255\n",
        "image = np.expand_dims(image, axis=0)\n",
        "\n",
        "prediction = model.predict(image)\n",
        "print(np.argmax(prediction))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uz-THdLwCAAr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "#Printing the accuracy and loss curves\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, color = 'b',label='Training acc')\n",
        "plt.plot(epochs, val_acc, color = 'g', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss,color = 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, color = 'g', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "################################################################################    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}